"""This script fixes some bespoke errors with the prepped fragalysis cache"""

import shutil
from pathlib import Path
from asapdiscovery.modeling.protein_prep import PreppedComplex
from asapdiscovery.data.backend.openeye import sdf_string_to_oemol
from asapdiscovery.data.schema.ligand import Ligand
import argparse
from asapdiscovery.data.util.logging import FileLogger
import rdkit


def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-i",
        "--input_cache",
        type=Path,
        help="Path to input cache generated by the asapdiscovery-data package.",
    )
    parser.add_argument(
        "-o",
        "--output_cache",
        type=Path,
        help="Path to output cache directory. If not provided, will create a copy with '_fixed' suffix.",
        default=None,
    )
    return parser.parse_args()


def main():
    args = get_args()
    input_cache = args.input_cache

    # Create output directory path if not provided
    if args.output_cache is None:
        output_cache = input_cache.parent / f"{input_cache.name}_fixed"
    else:
        output_cache = args.output_cache

    logger = FileLogger(
        "prep_cache_for_docking", input_cache, logfile="prep_cache_for_docking.log"
    ).getLogger()

    if not input_cache.exists():
        raise FileNotFoundError(f"Cache file {input_cache} not found")

    # Make a copy of the input directory
    logger.info(f"Creating copy of input cache '{input_cache}' to '{output_cache}'")
    if output_cache.exists():
        logger.warning(
            f"Output directory '{output_cache}' already exists. It will be overwritten."
        )
        shutil.rmtree(output_cache)

    shutil.copytree(input_cache, output_cache)
    logger.info(f"Copy created successfully at '{output_cache}'")

    # Now work on the copy instead of the original
    # Remove protein_prep.json and protein-prep.log from the copied cache as it confuses the cache loader
    for pattern in ["protein_prep.json", "protein-prep.log"]:
        for file_path in output_cache.glob(pattern):
            logger.info(f"Removing {file_path}")
            file_path.unlink()

    # fix ligand in P0097
    prepped_directories = list(output_cache.glob("*P0097*"))
    logger.info(
        f"Found {len(prepped_directories)} prepped directories in the copied cache: '{output_cache}'"
    )
    for prepped_directory in prepped_directories:
        ligand = prepped_directory / "MAT-POS-5d65ec79-1.sdf"
        if not ligand.exists():
            raise FileNotFoundError(f"Ligand file {ligand} not found")
        ligand = Ligand.from_sdf(ligand)
        # get rid of 2nd ligand
        rdmol = ligand.to_rdkit()

        # delete second fragment if it exists
        frags = [frag for frag in rdkit.Chem.GetMolFrags(rdmol)]
        if len(frags) == 2:
            logger.info(
                f"Found 2 fragments in ligand {ligand}, removing second fragment"
            )
            frag_to_delete = frags[1]
            editable = rdkit.Chem.EditableMol(rdmol)

            # need to change index as we delete
            # since the indices are already sorted, each time we delete one, the next will
            # have a lower index
            for i, idx in enumerate(frag_to_delete):
                idx = idx - i
                editable.RemoveAtom(idx)
            new_mol = editable.GetMol()
            rdkit.Chem.rdmolops.SanitizeMol(
                new_mol, sanitizeOps=rdkit.Chem.rdmolops.SANITIZE_ALL
            )
            sdf_str = rdkit.Chem.rdmolfiles.MolToMolBlock(new_mol)
            oemol = sdf_string_to_oemol(sdf_str)
            ligand = Ligand.from_oemol(oemol, compound_name=ligand.compound_name)
            ligand.to_sdf(prepped_directory / "MAT-POS-5d65ec79-1.sdf")

        # overwrite old json file
        json_file = list(prepped_directory.glob("*.json"))[0]
        prepped_complex = PreppedComplex.from_json_file(json_file)
        prepped_complex.ligand = ligand
        prepped_complex.to_json_file(json_file)

    logger.info(f"Processing complete. Modified data is in '{output_cache}'")
    # Mpro-P2243_0B
    # Mpro-P2214_0B


if __name__ == "__main__":
    main()
